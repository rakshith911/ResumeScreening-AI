{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n"
      ],
      "metadata": {
        "id": "n7_zHiwYd9NW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload resumes.csv to your Colab environment first (use the file upload button in Colab)\n",
        "df = pd.read_csv('resumes.csv')\n",
        "print(df.head())\n",
        "print(df['label'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6s5U1OxeMNg",
        "outputId": "e588c1d0-e8b5-4326-9425-777f397a7f2f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                         resume_text         label\n",
            "0  Data scientist proficient in Big Data, Pandas,...  Data Science\n",
            "1  Data scientist proficient in Python, Statistic...  Data Science\n",
            "2  Experienced software engineer with expertise i...           SWE\n",
            "3  Machine learning engineer skilled in Computer ...           MLE\n",
            "4  Machine learning engineer skilled in Spark, Da...           MLE\n",
            "label\n",
            "Data Science    179\n",
            "SWE             162\n",
            "MLE             159\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder()\n",
        "df['label_encoded'] = le.fit_transform(df['label'])\n",
        "print(list(le.classes_))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5duqY7YgePmJ",
        "outputId": "4f9c5f5c-2cdc-4a67-aafe-be279d372002"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Data Science', 'MLE', 'SWE']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
        "    df['resume_text'].tolist(),\n",
        "    df['label_encoded'].tolist(),\n",
        "    test_size=0.2,  # 20% for testing\n",
        "    random_state=42,\n",
        "    stratify=df['label_encoded']\n",
        ")\n",
        "print(f\"Train size: {len(train_texts)}, Test size: {len(test_texts)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2z2NpzcpOax",
        "outputId": "8c7637cc-b66c-4f74-b3ed-e529f1b304ab"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 400, Test size: 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=128)\n",
        "val_encodings = tokenizer(test_texts, truncation=True, padding=True, max_length=128)\n"
      ],
      "metadata": {
        "id": "VW7IQaqzpgLt"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=128)\n",
        "test_encodings = tokenizer(test_texts, truncation=True, padding=True, max_length=128)\n",
        "\n",
        "train_dataset = ResumeDataset(train_encodings, train_labels)\n",
        "test_dataset = ResumeDataset(test_encodings, test_labels)\n"
      ],
      "metadata": {
        "id": "ZKndiEN11Qcp"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResumeDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = ResumeDataset(train_encodings, train_labels)\n",
        "val_dataset = ResumeDataset(val_encodings, val_labels)\n"
      ],
      "metadata": {
        "id": "xKhhTtM3pim5"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    'bert-base-uncased',\n",
        "    num_labels=len(le.classes_)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDL1yQ8cplQe",
        "outputId": "8315a3d8-cbd5-4689-9510-b839e2ef6689"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=500,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    warmup_steps=10,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    eval_strategy='epoch',\n",
        "    save_strategy='epoch'\n",
        ")"
      ],
      "metadata": {
        "id": "jdenod2Tpmwm"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset\n",
        ")"
      ],
      "metadata": {
        "id": "z9dulBdkppUe"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = trainer.predict(test_dataset)\n",
        "y_pred = np.argmax(preds.predictions, axis=1)\n",
        "print(\"Test Accuracy:\", accuracy_score(test_labels, y_pred))\n",
        "print(classification_report(test_labels, y_pred, target_names=le.classes_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "DNgZoWnZpxzm",
        "outputId": "911b61aa-1b94-4cea-bbc0-89cb0bc648d5"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.32\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "Data Science       0.00      0.00      0.00        36\n",
            "         MLE       0.32      1.00      0.48        32\n",
            "         SWE       0.00      0.00      0.00        32\n",
            "\n",
            "    accuracy                           0.32       100\n",
            "   macro avg       0.11      0.33      0.16       100\n",
            "weighted avg       0.10      0.32      0.16       100\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained('./bert_resume_classifier')\n",
        "tokenizer.save_pretrained('./bert_resume_classifier')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K__n4Pcrpzko",
        "outputId": "fcee359f-9b55-4820-a9a1-4a13d5359731"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./bert_resume_classifier/tokenizer_config.json',\n",
              " './bert_resume_classifier/special_tokens_map.json',\n",
              " './bert_resume_classifier/vocab.txt',\n",
              " './bert_resume_classifier/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXsC29q-uHLc",
        "outputId": "f0e253b5-2949-4baf-a16b-7d9746547ee7"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_resume(text):\n",
        "    # Ensure model is on the correct device\n",
        "    device = next(model.parameters()).device\n",
        "    # Tokenize and move inputs to the model's device\n",
        "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=128)\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "    # Get model outputs\n",
        "    outputs = model(**inputs)\n",
        "    probs = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
        "    pred_label = torch.argmax(probs).item()\n",
        "    return le.inverse_transform([pred_label])[0], probs[0][pred_label].item()\n"
      ],
      "metadata": {
        "id": "2CfBdf9Lp1tW"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_text = \"Data scientist proficient in Jupyter, SQL, Statistics, Pandas, Machine Learning. Conducted analysis on sales transactions to uncover trends and support business decisions. Holds a Ph.D. in Machine Learning from MIT.\"\n",
        "predicted_class, confidence = predict_resume(test_text)\n",
        "print(f\"Predicted: {predicted_class} (confidence: {confidence:.2f})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NscUZ0VYuKBY",
        "outputId": "3df6c1ce-35ad-44c2-bdb2-ca125e4572cf"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: MLE (confidence: 0.59)\n"
          ]
        }
      ]
    }
  ]
}